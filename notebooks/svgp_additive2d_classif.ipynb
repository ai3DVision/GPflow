{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "from scipy.special import erf\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import cm \n",
    "%matplotlib inline\n",
    "import GPflow.kernels\n",
    "from GPflow.likelihoods import Bernoulli, Gaussian\n",
    "from GPflow.svgp import SVGP\n",
    "from GPflow.svgp_additive import SVGP_additive2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative model\n",
    "* $\\eta = \\alpha x_0 + f(x_1,x_2) $\n",
    "* $p(y|\\eta) \\quad \\text{some likelihood}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "N = 5000 # number of data points\n",
    "D = 3 # number of covariate dimension\n",
    "X = np.random.rand(N, D)-.5 # sampling covariates uniformly\n",
    "\n",
    "# some arbitrary functions    \n",
    "alpha = .5\n",
    "f = lambda x1,x2 : np.sin(x1*5.)*np.sin(x2*5.)\n",
    "\n",
    "    \n",
    "# Computing the additive predictor\n",
    "F = (alpha*X[:,0]+f(X[:,1],X[:,2])).reshape(N,1)\n",
    "\n",
    "# Computing the observables\n",
    "\n",
    "lik = 'Gaussian'\n",
    "#lik = 'Bernoulli'\n",
    "\n",
    "if lik == 'Gaussian':\n",
    "    s_n = .1\n",
    "    Y = F + np.random.randn(N,1) * s_n\n",
    "elif lik == 'Bernoulli':\n",
    "    phi =lambda x: 0.5*(1+erf(x/np.sqrt(2)))\n",
    "    B = phi(F)\n",
    "    Y = (np.random.rand(N,1)<B).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting individual functions\n",
    "l = .5\n",
    "xp = np.linspace(-l,l,200)\n",
    "X1g,X2g = np.meshgrid(xp,xp)\n",
    "plt.imshow(f(X1g,X2g),extent=[-l,l,-l,l])\n",
    "plt.xlabel('$x_1$',fontsize=20)\n",
    "plt.ylabel('$x_2$',fontsize=20)\n",
    "plt.title('function of 2 variables')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# histogram of predictor values\n",
    "plt.title('Predictor values')\n",
    "plt.hist(F)\n",
    "plt.xlabel('$\\sum_d f_d$',fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# Classification only: histogram of Bernoulli parameters\n",
    "if lik == 'Bernoulli':\n",
    "    plt.title('Bernoulli parameters values')\n",
    "    plt.hist(phi(F))\n",
    "    plt.xlabel('$\\phi ( \\sum_d f_d )$',fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inducing point locations \n",
    "Z = [np.array([[1]])] # one pseudo input for linear term\n",
    "Z+= [np.random.rand(30, 2)-.5] # (M,1) and (M,2) array\n",
    "    \n",
    "# Setting likelihood\n",
    "if lik == 'Gaussian':\n",
    "    likelihood = Gaussian()\n",
    "    likelihood.variance = 0.01\n",
    "elif lik == 'Bernoulli':\n",
    "    likelihood = Bernoulli()\n",
    "\n",
    "# Setting kernels\n",
    "ks = [GPflow.kernels.Linear(1)]\n",
    "ks += [ GPflow.kernels.RBF(2) ]\n",
    "\n",
    "f_indices=[[0],[1,2]] # covariate indices used by each function in additive decomposition\n",
    "n_func = len(f_indices)\n",
    "\n",
    "# Declaring model\n",
    "m = SVGP_additive2(X, Y, ks, likelihood, Z,f_indices=f_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing parameters\n",
    "Here, we decide which parameters we want to optimize. These include\n",
    "* kernel hyperparameters $\\theta$\n",
    "* inducing point locations $Z$\n",
    "* variational parameters\n",
    "* likelihood parameters (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- Kernel parameters\n",
    "for k in m.kerns.parameterized_list:\n",
    "    #if k.name == 'linear':\n",
    "    #    k.variance.fixed = True\n",
    "    #if k.name == 'rbf':\n",
    "    #    k.variance.fixed = True\n",
    "    #    k.lengthscales.fixed = True\n",
    "    pass\n",
    "        \n",
    "# --- Inducing points\n",
    "m.Z[0].fixed = True # no need to optimize location for linear parameter\n",
    "#for z in m.Z:\n",
    "#    z.fixed=True\n",
    "\n",
    "# --- Likelihood parameters\n",
    "if lik == 'Gaussian':\n",
    "    #m.likelihood.variance.fixed = True\n",
    "    pass\n",
    "\n",
    "\n",
    "# --- Variational parameters\n",
    "#for qmu in m.q_mu:\n",
    "    #qmu.fixed = True\n",
    "#for qs in m.q_sqrt:\n",
    "    #qs.fixed = True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# optimizing\n",
    "for k in range(2):\n",
    "    m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# computing predicted sum (mean and variance)\n",
    "Yp, Vp = m.predict_f(X)\n",
    "Sp = np.sqrt(Vp)\n",
    "\n",
    "# computing RootMeanSquaredError \n",
    "rmse = np.sqrt(np.mean((Yp - Y) ** 2))\n",
    "print \"RMSE: %.3f\" % rmse\n",
    "\n",
    "# plotting true against inferred predictor\n",
    "n = 100 #subselect plots\n",
    "I = np.random.randint(1,len(Y),n)\n",
    "fig,ax = plt.subplots()\n",
    "ax.errorbar(F,Yp , yerr=np.sqrt(Sp), fmt='o')\n",
    "lims = [ np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "         np.max([ax.get_xlim(), ax.get_ylim()])]\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax.set_xlabel('underlying predictor',fontsize=20)\n",
    "ax.set_ylabel('estimated predictor mean',fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generating predictions for individual functions\n",
    "Ys=[]\n",
    "Vs=[]\n",
    "for c in range(n_func):\n",
    "    m.set_prediction_subset_ds([c])\n",
    "    Yd, Vd = m.predict_f(X)\n",
    "    print c\n",
    "    Ys.append(Yd)\n",
    "    Vs.append(Vd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col=cm.rainbow(np.linspace(0,1,D))\n",
    "w = 5\n",
    "\n",
    "# plotting infered functions against true functions\n",
    "for c in range(n_func):\n",
    "    Yd = Ys[c]\n",
    "    Vd = Vs[c]\n",
    "\n",
    "    if len(f_indices[c])==1:\n",
    "        fig1,ax1 = plt.subplots()\n",
    "        d = f_indices[c][0]\n",
    "        o = np.argsort(X[:,d])\n",
    "        ax1.plot(X[o,d],alpha*X[o,d],'--',linewidth=4,c=col[d])\n",
    "        ax1.plot(X[o,d],Yd[o],'-',c=col[d])\n",
    "        ax1.fill_between(X[o,d],\n",
    "                         y1=np.squeeze(Yd[o]+np.sqrt(Vd[o])),\n",
    "                         y2=np.squeeze(Yd[o]-np.sqrt(Vd[o])),facecolor=col[d],alpha=.5)\n",
    "        ax1.set_xlabel('$x$ ',fontsize=20)\n",
    "        ax1.set_ylabel('$\\\\alpha x$ ',fontsize=20)\n",
    "        plt.show()\n",
    "        \n",
    "    elif len(f_indices[c])==2:\n",
    "        fig1,ax1 = plt.subplots()\n",
    "        ax1.scatter(X[o,f_indices[c][0]],\n",
    "                    X[o,f_indices[c][1]],\n",
    "                    c=Yd[o])\n",
    "        ax1.set_xlabel('$x_1$ ',fontsize=20)\n",
    "        ax1.set_ylabel('$x_2$ ',fontsize=20)\n",
    "        ax1.set_title('$f(x_1,x_2)$',fontsize=20)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "\n",
    "# plotting infered functions against true functions\n",
    "\n",
    "for c in range(n_func):\n",
    "    \n",
    "    Yd = Ys[c]\n",
    "    Vd = Vs[c]\n",
    "\n",
    "    if len(f_indices[c])==1:\n",
    "        d = f_indices[c][0]\n",
    "        fig,ax = plt.subplots()\n",
    "        ax.errorbar(alpha*X[o,d], Yd[o], yerr=np.sqrt(Vd), fmt='o')\n",
    "        lims = [ np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "                 np.max([ax.get_xlim(), ax.get_ylim()])]\n",
    "        ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "        ax.set_xlabel('underlying predictor',fontsize=20)\n",
    "        ax.set_ylabel('estimated predictor mean',fontsize=20)\n",
    "        plt.show()\n",
    "        \n",
    "    elif len(f_indices[c])==2:\n",
    "        fig,ax = plt.subplots()\n",
    "        ax.errorbar(F[o], Yd[o], yerr=np.sqrt(Vd), fmt='o')\n",
    "        lims = [ np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "                 np.max([ax.get_xlim(), ax.get_ylim()])]\n",
    "        ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "        ax.set_xlabel('underlying predictor',fontsize=20)\n",
    "        ax.set_ylabel('estimated predictor mean',fontsize=20)\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
